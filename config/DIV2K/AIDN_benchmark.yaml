DATA:
  data_name: DIV2K
  data_root: Data/DIV2K/
  train_set: list/train.txt
  val_set: list/val.txt
  loop: 1
  patch_size: 192
  hflip: True
  rotation: True
  rgb_range: 1.0
  debug: False
  balanceS: True

LOSS:
  loss_lr_weight: 1.0

NETWORK:
  base_resolution: 4
  arch: InvEDRS_arb
  up_sampler: sampleB
  down_sampler: sampleB
  n_resblocks: 16
  n_feats: 64
  fixed_scale: False
  scale: 4
  rescale:  # not used
  n_colors: 3
  res_scale: 1
  quantization: True
  quantization_type: round_soft
  K: 4
  num_experts_SAconv: 4
  num_experts_CRM: 8
  jpeg: False


TRAIN:
  use_sgd: False
  sync_bn: True  # adopt sync_bn or not
  train_gpu: [0,1,2,3]
  workers: 16  # data loader workers
  batch_size: 16  # batch size for training
  batch_size_val: 16  # batch size for validation during training, memory and speed tradeoff
  base_lr: 0.0001
  StepLR: True
  step_size: 60
  gamma: 0.5
  adaptive_lr: False
  factor: 0.3
  patience: 3
  threshold: 0.00025
  poly_lr: False
  epochs: 300
  start_epoch: 0
  power: 0.9
  momentum: 0.9
  weight_decay: 0.002
  manual_seed: 131
  print_freq: 10
  save_freq: 1
  save_path:
  weight: 
  resume:
  evaluate: True  # evaluate on validation set, extra gpu memory needed and small batch_size_val is recommend
  eval_freq: 1

Distributed:
  dist_url: tcp://127.0.0.1:6799
  dist_backend: 'nccl'
  multiprocessing_distributed: True
  world_size: 1
  rank: 0

TEST:
  exp_name: AIDN
  test_root: Data/
  # test_dataset: Set5+Set14+BSDS100+urban100
  test_dataset: Set5
  test_scale: 1.5+2.5+3.5
  save: False
  split: val
  test_workers: 2
  test_gpu: [0]
  test_batch_size: 1
  model_path:
  save_folder:
